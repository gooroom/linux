From a17b5611f5341b5e99a9cbd6db86ba7dd7e95266 Mon Sep 17 00:00:00 2001
Message-Id: <a17b5611f5341b5e99a9cbd6db86ba7dd7e95266.1601675152.git.zanussi@kernel.org>
In-Reply-To: <5b5a156f9808b1acf1205606e03da117214549ea.1601675151.git.zanussi@kernel.org>
References: <5b5a156f9808b1acf1205606e03da117214549ea.1601675151.git.zanussi@kernel.org>
From: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date: Fri, 4 Aug 2017 18:31:00 +0200
Subject: [PATCH 230/333] hotplug: duct-tape RT-rwlock usage for non-RT
Origin: https://www.kernel.org/pub/linux/kernel/projects/rt/4.19/older/patches-4.19.148-rt64.tar.xz

This type is only available on -RT. We need to craft something for
non-RT. Since the only migrate_disable() user is -RT only, there is no
damage.

Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
---
 kernel/cpu.c | 14 +++++++++++++-
 1 file changed, 13 insertions(+), 1 deletion(-)

diff --git a/kernel/cpu.c b/kernel/cpu.c
index f9e0e3db440a..8f5b80c0743b 100644
--- a/kernel/cpu.c
+++ b/kernel/cpu.c
@@ -76,7 +76,7 @@ static DEFINE_PER_CPU(struct cpuhp_cpu_state, cpuhp_state) = {
 	.fail = CPUHP_INVALID,
 };
 
-#ifdef CONFIG_HOTPLUG_CPU
+#if defined(CONFIG_HOTPLUG_CPU) && defined(CONFIG_PREEMPT_RT_FULL)
 static DEFINE_PER_CPU(struct rt_rw_lock, cpuhp_pin_lock) = \
 	__RWLOCK_RT_INITIALIZER(cpuhp_pin_lock);
 #endif
@@ -292,6 +292,7 @@ static int cpu_hotplug_disabled;
  */
 void pin_current_cpu(void)
 {
+#ifdef CONFIG_PREEMPT_RT_FULL
 	struct rt_rw_lock *cpuhp_pin;
 	unsigned int cpu;
 	int ret;
@@ -314,6 +315,7 @@ void pin_current_cpu(void)
 		goto again;
 	}
 	current->pinned_on_cpu = cpu;
+#endif
 }
 
 /**
@@ -321,6 +323,7 @@ void pin_current_cpu(void)
  */
 void unpin_current_cpu(void)
 {
+#ifdef CONFIG_PREEMPT_RT_FULL
 	struct rt_rw_lock *cpuhp_pin = this_cpu_ptr(&cpuhp_pin_lock);
 
 	if (WARN_ON(current->pinned_on_cpu != smp_processor_id()))
@@ -328,6 +331,7 @@ void unpin_current_cpu(void)
 
 	current->pinned_on_cpu = -1;
 	__read_rt_unlock(cpuhp_pin);
+#endif
 }
 
 DEFINE_STATIC_PERCPU_RWSEM(cpu_hotplug_lock);
@@ -902,7 +906,9 @@ static int take_cpu_down(void *_param)
 
 static int takedown_cpu(unsigned int cpu)
 {
+#ifdef CONFIG_PREEMPT_RT_FULL
 	struct rt_rw_lock *cpuhp_pin = per_cpu_ptr(&cpuhp_pin_lock, cpu);
+#endif
 	struct cpuhp_cpu_state *st = per_cpu_ptr(&cpuhp_state, cpu);
 	int err;
 
@@ -915,14 +921,18 @@ static int takedown_cpu(unsigned int cpu)
 	 */
 	irq_lock_sparse();
 
+#ifdef CONFIG_PREEMPT_RT_FULL
 	__write_rt_lock(cpuhp_pin);
+#endif
 
 	/*
 	 * So now all preempt/rcu users must observe !cpu_active().
 	 */
 	err = stop_machine_cpuslocked(take_cpu_down, NULL, cpumask_of(cpu));
 	if (err) {
+#ifdef CONFIG_PREEMPT_RT_FULL
 		__write_rt_unlock(cpuhp_pin);
+#endif
 		/* CPU refused to die */
 		irq_unlock_sparse();
 		/* Unpark the hotplug thread so we can rollback there */
@@ -941,7 +951,9 @@ static int takedown_cpu(unsigned int cpu)
 	wait_for_ap_thread(st, false);
 	BUG_ON(st->state != CPUHP_AP_IDLE_DEAD);
 
+#ifdef CONFIG_PREEMPT_RT_FULL
 	__write_rt_unlock(cpuhp_pin);
+#endif
 	/* Interrupts are moved away from the dying cpu, reenable alloc/free */
 	irq_unlock_sparse();
 
-- 
2.17.1

