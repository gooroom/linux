From 4e1b08e237d8c4cb01a39c14daea9c140417cce4 Mon Sep 17 00:00:00 2001
Message-Id: <4e1b08e237d8c4cb01a39c14daea9c140417cce4.1610128659.git.zanussi@kernel.org>
In-Reply-To: <f6355f395156d91294a3a1cd62e05e137dda13d5.1610128658.git.zanussi@kernel.org>
References: <f6355f395156d91294a3a1cd62e05e137dda13d5.1610128658.git.zanussi@kernel.org>
From: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date: Wed, 13 Sep 2017 12:32:34 +0200
Subject: [PATCH 171/335] fs/dcache: bring back explicit INIT_HLIST_BL_HEAD
 init
Origin: https://www.kernel.org/pub/linux/kernel/projects/rt/4.19/older/patches-4.19.165-rt70.tar.xz

Commit 3d375d78593c ("mm: update callers to use HASH_ZERO flag") removed
INIT_HLIST_BL_HEAD and uses the ZERO flag instead for the init. However
on RT we have also a spinlock which needs an init call so we can't use
that.

Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
---
 fs/dcache.c | 11 +++++++++++
 1 file changed, 11 insertions(+)

diff --git a/fs/dcache.c b/fs/dcache.c
index 1897833a4668..b5e53587d14b 100644
--- a/fs/dcache.c
+++ b/fs/dcache.c
@@ -3077,6 +3077,8 @@ __setup("dhash_entries=", set_dhash_entries);
 
 static void __init dcache_init_early(void)
 {
+	unsigned int loop;
+
 	/* If hashes are distributed across NUMA nodes, defer
 	 * hash allocation until vmalloc space is available.
 	 */
@@ -3093,11 +3095,16 @@ static void __init dcache_init_early(void)
 					NULL,
 					0,
 					0);
+
+	for (loop = 0; loop < (1U << d_hash_shift); loop++)
+		INIT_HLIST_BL_HEAD(dentry_hashtable + loop);
+
 	d_hash_shift = 32 - d_hash_shift;
 }
 
 static void __init dcache_init(void)
 {
+	unsigned int loop;
 	/*
 	 * A constructor could be added for stable state like the lists,
 	 * but it is probably not worth it because of the cache nature
@@ -3121,6 +3128,10 @@ static void __init dcache_init(void)
 					NULL,
 					0,
 					0);
+
+	for (loop = 0; loop < (1U << d_hash_shift); loop++)
+		INIT_HLIST_BL_HEAD(dentry_hashtable + loop);
+
 	d_hash_shift = 32 - d_hash_shift;
 }
 
-- 
2.17.1

