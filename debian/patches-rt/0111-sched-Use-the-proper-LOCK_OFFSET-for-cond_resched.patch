From b63cd21ec112a059fe8acbab6214652a21b8fb73 Mon Sep 17 00:00:00 2001
Message-Id: <b63cd21ec112a059fe8acbab6214652a21b8fb73.1599166690.git.zanussi@kernel.org>
In-Reply-To: <56457dc415803c8abc5acb513ada877a79596f05.1599166690.git.zanussi@kernel.org>
References: <56457dc415803c8abc5acb513ada877a79596f05.1599166690.git.zanussi@kernel.org>
From: Thomas Gleixner <tglx@linutronix.de>
Date: Sun, 17 Jul 2011 22:51:33 +0200
Subject: [PATCH 111/333] sched: Use the proper LOCK_OFFSET for cond_resched()
Origin: https://www.kernel.org/pub/linux/kernel/projects/rt/4.19/older/patches-4.19.142-rt63.tar.xz

RT does not increment preempt count when a 'sleeping' spinlock is
locked. Update PREEMPT_LOCK_OFFSET for that case.

Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
---
 include/linux/preempt.h | 4 ++++
 1 file changed, 4 insertions(+)

diff --git a/include/linux/preempt.h b/include/linux/preempt.h
index f7a17fcc3fec..b7fe717eb1f4 100644
--- a/include/linux/preempt.h
+++ b/include/linux/preempt.h
@@ -118,7 +118,11 @@
 /*
  * The preempt_count offset after spin_lock()
  */
+#if !defined(CONFIG_PREEMPT_RT_FULL)
 #define PREEMPT_LOCK_OFFSET	PREEMPT_DISABLE_OFFSET
+#else
+#define PREEMPT_LOCK_OFFSET	0
+#endif
 
 /*
  * The preempt_count offset needed for things like:
-- 
2.17.1

