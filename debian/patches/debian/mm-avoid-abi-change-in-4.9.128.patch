From: Ben Hutchings <ben@decadent.org.uk>
Date: Thu, 20 Sep 2018 21:33:48 +0100
Subject: mm: Avoid ABI change in 4.9.128
Forwarded: not-needed

Commit 84580567f1f8 "mm: get rid of vmacache_flush_all() entirely"
changed the type (and size) of mm_struct::vmacache_seqnum and
task_struct::vmacache_seqnum.

This field is only used by the built-in vmacache code, and the
structures are always allocated by the core kernel, so it should
be safe to move the fields to the end of each structure and add
padding in place of the old location.

However, task_struct is really dynamically-sized on s390 and x86
and we can't safely access another field at the end.  Instead,
define a new struct task_struct_ext containing the larger field,
and:

- Add space for this to the end of struct task_struct.  s390 and
  x86 calculate the dynamic structure size by subtracting from
  sizeof(struct task_struct) rather than using offsetof(), so they
  will include this extra space in the dynamic size.
- Define a task_ext() function to find the task_struct_ext at the
  end of a task_struct, using the dynamic structure size.
- Use task_ext() in the vmacache code to access the larger field.
- [x86] Adjust the structure layout check in
  fpu__init_task_struct_size for this.

---
--- a/include/linux/mm_types.h
+++ b/include/linux/mm_types.h
@@ -398,7 +398,11 @@ struct kioctx_table;
 struct mm_struct {
 	struct vm_area_struct *mmap;		/* list of VMAs */
 	struct rb_root mm_rb;
-	u64 vmacache_seqnum;                   /* per-thread vmacache */
+#ifndef __GENKSYMS__
+	u32 __pad_was_vmacache_seqnum;
+#else
+	u32 vmacache_seqnum;
+#endif
 #ifdef CONFIG_MMU
 	unsigned long (*get_unmapped_area) (struct file *filp,
 				unsigned long addr, unsigned long len,
@@ -523,6 +527,9 @@ struct mm_struct {
 	atomic_long_t hugetlb_usage;
 #endif
 	struct work_struct async_put_work;
+#ifndef __GENKSYMS__
+	u64 vmacache_seqnum;                   /* per-thread vmacache */
+#endif
 };
 
 static inline void mm_init_cpumask(struct mm_struct *mm)
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -1483,6 +1483,12 @@ struct tlbflush_unmap_batch {
 	bool writable;
 };
 
+#ifndef MODULE
+struct task_struct_ext {
+	u64 vmacache_seqnum;                   /* per-thread vmacache */
+};
+#endif
+
 struct task_struct {
 #ifdef CONFIG_THREAD_INFO_IN_TASK
 	/*
@@ -1559,7 +1565,11 @@ struct task_struct {
 
 	struct mm_struct *mm, *active_mm;
 	/* per-thread vma caching */
-	u64 vmacache_seqnum;
+#ifndef __GENKSYMS__
+	u32 __pad_was_vmacache_seqnum;
+#else
+	u32 vmacache_seqnum;
+#endif
 	struct vm_area_struct *vmacache[VMACACHE_SIZE];
 #if defined(SPLIT_RSS_COUNTING)
 	struct task_rss_stat	rss_stat;
@@ -1979,6 +1989,10 @@ struct task_struct {
  *
  * Do not put anything below here!
  */
+#if !defined(__GENKSYMS__) && !defined(MODULE)
+	/* bwh: Use task_ext() rather than accessing this field directly */
+	struct task_struct_ext __pad_for_ext;
+#endif
 };
 
 #ifdef CONFIG_ARCH_WANTS_DYNAMIC_TASK_STRUCT
@@ -1987,6 +2001,13 @@ extern int arch_task_struct_size __read_
 # define arch_task_struct_size (sizeof(struct task_struct))
 #endif
 
+#if !defined(__GENKSYMS__) && !defined(MODULE)
+static inline struct task_struct_ext *task_ext(struct task_struct *t)
+{
+	return (struct task_struct_ext *)((char *)t + arch_task_struct_size) - 1;
+}
+#endif
+
 #ifdef CONFIG_VMAP_STACK
 static inline struct vm_struct *task_stack_vm_area(const struct task_struct *t)
 {
--- a/mm/vmacache.c
+++ b/mm/vmacache.c
@@ -33,12 +33,12 @@ static bool vmacache_valid(struct mm_str
 		return false;
 
 	curr = current;
-	if (mm->vmacache_seqnum != curr->vmacache_seqnum) {
+	if (mm->vmacache_seqnum != task_ext(curr)->vmacache_seqnum) {
 		/*
 		 * First attempt will always be invalid, initialize
 		 * the new cache for this task here.
 		 */
-		curr->vmacache_seqnum = mm->vmacache_seqnum;
+		task_ext(curr)->vmacache_seqnum = mm->vmacache_seqnum;
 		vmacache_flush(curr);
 		return false;
 	}
--- a/arch/x86/kernel/fpu/init.c
+++ b/arch/x86/kernel/fpu/init.c
@@ -187,7 +187,10 @@ static void __init fpu__init_task_struct
 	 */
 	CHECK_MEMBER_AT_END_OF(struct fpu, state);
 	CHECK_MEMBER_AT_END_OF(struct thread_struct, fpu);
-	CHECK_MEMBER_AT_END_OF(struct task_struct, thread);
+	BUILD_BUG_ON(sizeof(struct task_struct) !=
+		     ALIGN(offsetofend(struct task_struct, thread) +
+			   sizeof(struct task_struct_ext),
+			   TYPE_ALIGN(struct task_struct)));
 
 	arch_task_struct_size = task_size;
 }
