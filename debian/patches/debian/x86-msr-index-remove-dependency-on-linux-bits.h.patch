From: Ben Hutchings <ben@decadent.org.uk>
Date: Sun, 12 May 2019 13:58:04 +0100
Subject: x86/msr-index: Remove dependency on <linux/bits.h>
Forwarded: not-needed

The x86 <asm/msr-index.h> header is (mistakenly) exported as a UAPI
header in 4.9.  Adding the inclusion of <linux/bits.h> stops that
working entirely as that header isn't exported.

This will likely be resolved upstream by un-exporting
<asm/msr-index.h>.  However, to avoid build regressions for user-space
in stretch, we should keep it working as a UAPI header.

Remove the inclusion of <linux/bits.h> and open-code BIT() for the
recently converted definitions.  There are other bits defined with
BIT_ULL() which won't work in user-space, but that's not a regression.
---
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -1,8 +1,6 @@
 #ifndef _ASM_X86_MSR_INDEX_H
 #define _ASM_X86_MSR_INDEX_H
 
-#include <linux/bits.h>
-
 /*
  * CPU model specific register (MSR) numbers.
  *
@@ -40,14 +38,14 @@
 
 /* Intel MSRs. Some also available on other CPUs */
 #define MSR_IA32_SPEC_CTRL		0x00000048 /* Speculation Control */
-#define SPEC_CTRL_IBRS			BIT(0)	   /* Indirect Branch Restricted Speculation */
+#define SPEC_CTRL_IBRS			(1UL << 0) /* Indirect Branch Restricted Speculation */
 #define SPEC_CTRL_STIBP_SHIFT		1	   /* Single Thread Indirect Branch Predictor (STIBP) bit */
-#define SPEC_CTRL_STIBP			BIT(SPEC_CTRL_STIBP_SHIFT)	/* STIBP mask */
+#define SPEC_CTRL_STIBP			(1UL << SPEC_CTRL_STIBP_SHIFT) /* STIBP mask */
 #define SPEC_CTRL_SSBD_SHIFT		2	   /* Speculative Store Bypass Disable bit */
-#define SPEC_CTRL_SSBD			BIT(SPEC_CTRL_SSBD_SHIFT)	/* Speculative Store Bypass Disable */
+#define SPEC_CTRL_SSBD			(1UL << SPEC_CTRL_SSBD_SHIFT) /* Speculative Store Bypass Disable */
 
 #define MSR_IA32_PRED_CMD		0x00000049 /* Prediction Command */
-#define PRED_CMD_IBPB			BIT(0)	   /* Indirect Branch Prediction Barrier */
+#define PRED_CMD_IBPB			(1UL << 0) /* Indirect Branch Prediction Barrier */
 
 #define MSR_IA32_PERFCTR0		0x000000c1
 #define MSR_IA32_PERFCTR1		0x000000c2
@@ -64,25 +62,25 @@
 #define MSR_MTRRcap			0x000000fe
 
 #define MSR_IA32_ARCH_CAPABILITIES	0x0000010a
-#define ARCH_CAP_RDCL_NO		BIT(0)	/* Not susceptible to Meltdown */
-#define ARCH_CAP_IBRS_ALL		BIT(1)	/* Enhanced IBRS support */
-#define ARCH_CAP_SKIP_VMENTRY_L1DFLUSH	BIT(3)	/* Skip L1D flush on vmentry */
-#define ARCH_CAP_SSB_NO			BIT(4)	/*
-						 * Not susceptible to Speculative Store Bypass
-						 * attack, so no Speculative Store Bypass
-						 * control required.
-						 */
-#define ARCH_CAP_MDS_NO			BIT(5)   /*
-						  * Not susceptible to
-						  * Microarchitectural Data
-						  * Sampling (MDS) vulnerabilities.
-						  */
+#define ARCH_CAP_RDCL_NO		(1UL << 0) /* Not susceptible to Meltdown */
+#define ARCH_CAP_IBRS_ALL		(1UL << 1) /* Enhanced IBRS support */
+#define ARCH_CAP_SKIP_VMENTRY_L1DFLUSH	(1UL << 3) /* Skip L1D flush on vmentry */
+#define ARCH_CAP_SSB_NO			(1UL << 4) /*
+						    * Not susceptible to Speculative Store Bypass
+						    * attack, so no Speculative Store Bypass
+						    * control required.
+						    */
+#define ARCH_CAP_MDS_NO			(1UL << 5) /*
+						    * Not susceptible to
+						    * Microarchitectural Data
+						    * Sampling (MDS) vulnerabilities.
+						    */
 
 #define MSR_IA32_FLUSH_CMD		0x0000010b
-#define L1D_FLUSH			BIT(0)	/*
-						 * Writeback and invalidate the
-						 * L1 data cache.
-						 */
+#define L1D_FLUSH			(1UL << 0) /*
+						    * Writeback and invalidate the
+						    * L1 data cache.
+						    */
 
 #define MSR_IA32_BBL_CR_CTL		0x00000119
 #define MSR_IA32_BBL_CR_CTL3		0x0000011e
